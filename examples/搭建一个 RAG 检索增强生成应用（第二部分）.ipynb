{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:33:49.326204Z",
     "start_time": "2025-11-26T10:33:49.305649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "f7484537688fc7eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "40561540628451fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:14.370313Z",
     "start_time": "2025-11-26T10:34:14.167558Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI(model=\"qwen-plus\")",
   "id": "847959acbc362eb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:16.110653Z",
     "start_time": "2025-11-26T10:34:15.997723Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings = DashScopeEmbeddings(model=\"text-embedding-v3\")",
   "id": "2157204c39ad746e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:17.171046Z",
     "start_time": "2025-11-26T10:34:17.119067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ],
   "id": "fd5c788884449474",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chains",
   "id": "1de82f57bd827779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:27.468558Z",
     "start_time": "2025-11-26T10:34:26.505412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ],
   "id": "daa008126f8b0dd9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:26.503876Z",
     "start_time": "2025-11-26T10:34:21.093465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ],
   "id": "13cf75e551ee1a31",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:31.024761Z",
     "start_time": "2025-11-26T10:34:30.982117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ],
   "id": "df60bbaa771f472f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:34:52.710797Z",
     "start_time": "2025-11-26T10:34:52.693642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query when the answer is not known.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    print(f\"Retrieved: {serialized}\")\n",
    "    print(f\"retrieved_docs: {retrieved_docs}\")\n",
    "    return serialized, retrieved_docs"
   ],
   "id": "b7690ad7953a2a47",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:36:48.425850Z",
     "start_time": "2025-11-26T10:36:48.392670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "           or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ],
   "id": "15264b3503cf6e3d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:36:59.309194Z",
     "start_time": "2025-11-26T10:36:58.808524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\"query_or_respond\",\n",
    "                                    tools_condition,\n",
    "                                    {END: END, \"tools\": \"tools\"})\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "c6d85c350fa1b602",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:37:01.053284Z",
     "start_time": "2025-11-26T10:37:00.131865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "        stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "74072fc7378c00a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:37:08.607970Z",
     "start_time": "2025-11-26T10:37:04.971352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"What is Task Decomposition mentioned in the blog?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "id": "d876e4ff614e373d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is Task Decomposition mentioned in the blog?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_6152374e62bd45d9b022bf)\n",
      " Call ID: call_6152374e62bd45d9b022bf\n",
      "  Args:\n",
      "    query: Task Decomposition blog\n",
      "Retrieved: Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "retrieved_docs: [Document(id='46cac9fd-5766-4a9a-ac8f-cc8123c7003e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='7153c450-6d86-4bc6-811d-64a74b3acef2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')]\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. It can be achieved using techniques like chain-of-thought prompting, where an LLM is instructed to \"think step by step,\" or through external methods like using a classical planner with PDDL in the LLM+P approach. It can also involve human input or task-specific instructions to guide the breakdown of tasks.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:14:17.427553Z",
     "start_time": "2025-02-22T09:14:17.424955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for message in event['messages']:\n",
    "    message.pretty_print()"
   ],
   "id": "d1218fbd14e55acf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is Task Decomposition mentioned in the blog?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_7714404c518c41c2a202ed)\n",
      " Call ID: call_7714404c518c41c2a202ed\n",
      "  Args:\n",
      "    query: Task Decomposition mentioned in the blog\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Task Decomposition is a method where complex tasks are broken down into smaller, simpler steps. This can be achieved through techniques like Chain of Thought (CoT), which instructs the model to think step by step, or Tree of Thoughts, which explores multiple reasoning possibilities at each step, creating a tree structure. These methods help in managing and interpreting the model's thinking process.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stateful management of chat history",
   "id": "c4822cb787b43527"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:19:04.237901Z",
     "start_time": "2025-02-22T09:19:04.233347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ],
   "id": "f64bec4dabf7fae9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:19:11.434894Z",
     "start_time": "2025-02-22T09:19:05.256713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"What is Task Decomposition mentioned in the blog?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "        stream_mode=\"values\",\n",
    "        config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "5697664810cfc2d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is Task Decomposition mentioned in the blog?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_22891b380f244b4aa3b210)\n",
      " Call ID: call_22891b380f244b4aa3b210\n",
      "  Args:\n",
      "    query: Task Decomposition mentioned in the blog\n",
      "Retrieved: Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "retrieved_docs: [Document(id='1ac78d6b-12f4-4282-9bf7-ba8811df82dc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='60b3f3d6-cf57-443f-a322-90af990f6006', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Task Decomposition is a method where complex tasks are broken down into smaller, more manageable steps. This can be achieved through techniques like Chain of Thought (CoT), which instructs the model to think step by step, or Tree of Thoughts, which explores multiple reasoning possibilities at each step. These approaches help in simplifying the task and making the model's thinking process more interpretable.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T10:38:18.196259Z",
     "start_time": "2025-11-26T10:38:18.054026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"Can you look up some common ways of doing it in the blog?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "        stream_mode=\"values\",\n",
    "        config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "aef5f90a911ca05a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      1\u001B[39m input_message = \u001B[33m\"\u001B[39m\u001B[33mCan you look up some common ways of doing it in the blog?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m graph.stream(\n\u001B[32m      4\u001B[39m         {\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: input_message}]},\n\u001B[32m      5\u001B[39m         stream_mode=\u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m         config=\u001B[43mconfig\u001B[49m,\n\u001B[32m      7\u001B[39m ):\n\u001B[32m      8\u001B[39m     step[\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m][-\u001B[32m1\u001B[39m].pretty_print()\n",
      "\u001B[31mNameError\u001B[39m: name 'config' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:21:08.370056Z",
     "start_time": "2025-02-22T09:21:08.365222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snape = graph.get_state(config)\n",
    "for message in snape.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "97035f5a7cc89580",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is Task Decomposition mentioned in the blog?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_22891b380f244b4aa3b210)\n",
      " Call ID: call_22891b380f244b4aa3b210\n",
      "  Args:\n",
      "    query: Task Decomposition mentioned in the blog\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Task Decomposition is a method where complex tasks are broken down into smaller, more manageable steps. This can be achieved through techniques like Chain of Thought (CoT), which instructs the model to think step by step, or Tree of Thoughts, which explores multiple reasoning possibilities at each step. These approaches help in simplifying the task and making the model's thinking process more interpretable.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it in the blog?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "According to the blog, there are three common ways of performing task decomposition:\n",
      "\n",
      "1. **Using LLM with Simple Prompting:** You can prompt the model with simple instructions like \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\".\n",
      "2. **Using Task-Specific Instructions:** For specific tasks, you can provide more tailored instructions. For example, if the task is writing a novel, you could use a prompt such as \"Write a story outline.\"\n",
      "3. **With Human Inputs:** Incorporating human guidance into the process, where humans can help define the steps or sub-tasks necessary for completing the larger task.\n",
      "\n",
      "These methods allow for the effective breakdown of complex tasks into smaller, more manageable components.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agents",
   "id": "cfb843a9764fc044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:28:10.637270Z",
     "start_time": "2025-02-22T09:28:10.101433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ],
   "id": "67b02255dd938d47",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:30:17.452736Z",
     "start_time": "2025-02-22T09:29:38.684761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def2345\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition in the bolg?\\n\\n\"\n",
    "    \"Once you get the answer from bolg with tool, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "        stream_mode=\"values\",\n",
    "        config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "id": "941c3a4e50e7cb55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition in the bolg?\n",
      "\n",
      "Once you get the answer from bolg with tool, look up common extensions of that method.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_7832229a9c52424e8f5b8b)\n",
      " Call ID: call_7832229a9c52424e8f5b8b\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition in the blog\n",
      "Retrieved: Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "retrieved_docs: [Document(id='60b3f3d6-cf57-443f-a322-90af990f6006', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='1ac78d6b-12f4-4282-9bf7-ba8811df82dc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.')]\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The standard method for task decomposition in the blog is the Chain of Thought (CoT) approach, which was introduced by Wei et al. in 2022. This technique involves instructing a model to \"think step by step,\" thereby breaking down complex tasks into smaller and more manageable steps. It helps to utilize more test-time computation and also provides insight into the model's thought process.\n",
      "\n",
      "The CoT can be extended using a method called Tree of Thoughts (Yao et al. 2023), which further expands upon the CoT by exploring multiple reasoning possibilities at each step. In this method, the problem is decomposed into several thought steps, and multiple thoughts are generated per step, forming a tree structure. The search through this tree can be conducted with either breadth-first search (BFS) or depth-first search (DFS), and states can be evaluated using a classifier or majority vote.\n",
      "\n",
      "Task decomposition can be achieved in a few different ways:\n",
      "\n",
      "1. By using an LLM (Language Model) with simple prompts, such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2. By applying task-specific instructions, like providing a prompt \"Write a story outline\" when writing a novel.\n",
      "3. With the help of human input to guide the decomposition process.\n",
      "\n",
      "Let's now look up the common extensions of the Chain of Thought (CoT) method.\n",
      "Tool Calls:\n",
      "  retrieve (call_55b9fefba6cd445d97101a)\n",
      " Call ID: call_55b9fefba6cd445d97101a\n",
      "  Args:\n",
      "    query: common extensions of the Chain of Thought (CoT) method\n",
      "Retrieved: Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "retrieved_docs: [Document(id='60b3f3d6-cf57-443f-a322-90af990f6006', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='85c3027a-3d96-46ec-baa3-67b5d7bd003d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.')]\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The Chain of Thought (CoT) method, which is a technique for enhancing model performance on complex tasks by breaking them down into smaller steps, has been extended in a few notable ways:\n",
      "\n",
      "1. **Tree of Thoughts (ToT)**: Introduced by Yao et al. (2023), ToT builds upon CoT by creating a more extensive reasoning process. It decomposes the problem into multiple thought steps and generates several thoughts per step, resulting in a tree structure. This allows the exploration of multiple reasoning paths. The search through the tree can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state being evaluated by a classifier or by majority vote. This approach is particularly useful for knowledge-intensive tasks and decision-making tasks, as it enables the agent to explore different lines of reasoning and potentially arrive at better solutions.\n",
      "\n",
      "2. **ReAct (Reason + Act)**: Although not an extension of CoT per se, ReAct is a framework that complements the idea of reasoning before acting. In this setup, the agent reasons about the next action (Thought) before actually taking it (Act). When compared to an Act-only baseline, where the reasoning step is omitted, ReAct has shown superior performance on both knowledge-intensive and decision-making tasks. The reasoning component of ReAct adds an additional layer of deliberation, which can lead to more informed actions.\n",
      "\n",
      "3. **Reflexion**: Proposed by Shinn & Labash (2023), Reflexion equips agents with dynamic memory and self-reflection capabilities to improve their reasoning skills. It uses a standard reinforcement learning (RL) setup, where the reward model provides binary feedback, and the action space is enhanced with language to facilitate complex reasoning. After performing an action, the agent calculates a heuristic and may decide to reset the environment and start a new trial based on its self-reflection. This self-reflective mechanism allows the agent to learn from its experiences and adjust its strategy, which can be seen as an indirect extension of the CoT concept, as it involves iterative thinking and adjustment.\n",
      "\n",
      "These extensions aim to enhance the original CoT by incorporating more sophisticated reasoning, self-reflection, and decision-making processes, making the models more capable of handling complex and dynamic tasks.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:30:17.534086Z",
     "start_time": "2025-02-22T09:30:17.524200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snape = graph.get_state(config)\n",
    "for message in snape.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "6827f1d1c7a41a2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition in the bolg?\n",
      "\n",
      "Once you get the answer from bolg with tool, look up common extensions of that method.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_7832229a9c52424e8f5b8b)\n",
      " Call ID: call_7832229a9c52424e8f5b8b\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition in the blog\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The standard method for task decomposition in the blog is the Chain of Thought (CoT) approach, which was introduced by Wei et al. in 2022. This technique involves instructing a model to \"think step by step,\" thereby breaking down complex tasks into smaller and more manageable steps. It helps to utilize more test-time computation and also provides insight into the model's thought process.\n",
      "\n",
      "The CoT can be extended using a method called Tree of Thoughts (Yao et al. 2023), which further expands upon the CoT by exploring multiple reasoning possibilities at each step. In this method, the problem is decomposed into several thought steps, and multiple thoughts are generated per step, forming a tree structure. The search through this tree can be conducted with either breadth-first search (BFS) or depth-first search (DFS), and states can be evaluated using a classifier or majority vote.\n",
      "\n",
      "Task decomposition can be achieved in a few different ways:\n",
      "\n",
      "1. By using an LLM (Language Model) with simple prompts, such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2. By applying task-specific instructions, like providing a prompt \"Write a story outline\" when writing a novel.\n",
      "3. With the help of human input to guide the decomposition process.\n",
      "\n",
      "Let's now look up the common extensions of the Chain of Thought (CoT) method.\n",
      "Tool Calls:\n",
      "  retrieve (call_55b9fefba6cd445d97101a)\n",
      " Call ID: call_55b9fefba6cd445d97101a\n",
      "  Args:\n",
      "    query: common extensions of the Chain of Thought (CoT) method\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The Chain of Thought (CoT) method, which is a technique for enhancing model performance on complex tasks by breaking them down into smaller steps, has been extended in a few notable ways:\n",
      "\n",
      "1. **Tree of Thoughts (ToT)**: Introduced by Yao et al. (2023), ToT builds upon CoT by creating a more extensive reasoning process. It decomposes the problem into multiple thought steps and generates several thoughts per step, resulting in a tree structure. This allows the exploration of multiple reasoning paths. The search through the tree can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state being evaluated by a classifier or by majority vote. This approach is particularly useful for knowledge-intensive tasks and decision-making tasks, as it enables the agent to explore different lines of reasoning and potentially arrive at better solutions.\n",
      "\n",
      "2. **ReAct (Reason + Act)**: Although not an extension of CoT per se, ReAct is a framework that complements the idea of reasoning before acting. In this setup, the agent reasons about the next action (Thought) before actually taking it (Act). When compared to an Act-only baseline, where the reasoning step is omitted, ReAct has shown superior performance on both knowledge-intensive and decision-making tasks. The reasoning component of ReAct adds an additional layer of deliberation, which can lead to more informed actions.\n",
      "\n",
      "3. **Reflexion**: Proposed by Shinn & Labash (2023), Reflexion equips agents with dynamic memory and self-reflection capabilities to improve their reasoning skills. It uses a standard reinforcement learning (RL) setup, where the reward model provides binary feedback, and the action space is enhanced with language to facilitate complex reasoning. After performing an action, the agent calculates a heuristic and may decide to reset the environment and start a new trial based on its self-reflection. This self-reflective mechanism allows the agent to learn from its experiences and adjust its strategy, which can be seen as an indirect extension of the CoT concept, as it involves iterative thinking and adjustment.\n",
      "\n",
      "These extensions aim to enhance the original CoT by incorporating more sophisticated reasoning, self-reflection, and decision-making processes, making the models more capable of handling complex and dynamic tasks.\n"
     ]
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
